{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "#x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=3\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sliding_window(df,window_size,window_stride,input_features=None, output_features=None):\n",
    "    #print(df.columns)\n",
    "    #print(df[input_features])\n",
    "    #print(df[input_features].values)\n",
    "    allData = df[input_features].values.tolist()\n",
    "    if output_features:\n",
    "        outputData = [i[0] for i in df[output_features].values.tolist()]\n",
    "    #print(outputData)\n",
    "    myArray = [[]]\n",
    "    outputDataArray = [] \n",
    "    start=0\n",
    "    for i in range(0,len(allData),window_stride):\n",
    "        #print(allData[i:window_size+i])\n",
    "        #print(i)\n",
    "        if i == 0:\n",
    "            myArray = [allData[i:window_size+i]]\n",
    "            if output_features != None:\n",
    "                #outputDataArray.append(outputData[window_size+i][0])\n",
    "                outputDataArray=[outputData[i+window_size-1]]\n",
    "                #print(1,type(outputDataArray))\n",
    "        else:\n",
    "            myArray.append(allData[i:window_size+i])\n",
    "            \n",
    "            if window_size+i >= len(allData):\n",
    "                if output_features != None:\n",
    "                    #print(2,type(outputDataArray))\n",
    "                    outputDataArray.append(outputData[len(allData)-1])\n",
    "                break\n",
    "            if output_features != None:\n",
    "                    #outputDataArray.append(outputData[window_size+i][0])\n",
    "                    #print(3,type(outputDataArray))\n",
    "                    outputDataArray.append(outputData[i+window_size-1])\n",
    "\n",
    "    if output_features == None:\n",
    "            return (np.array(myArray))\n",
    "    print(np.shape(np.array(myArray)))\n",
    "    #return (np.array(myArray), outputDataArray)\n",
    "    return (myArray, outputDataArray)\n",
    "\n",
    "def mystratifiedOutputSampler(df, target):\n",
    "    #a = {i:[] for i in df[target].unique()}\n",
    "    xTIndexes = []\n",
    "    minLen = None\n",
    "    #print(a)\n",
    "    for i in df[target].unique():\n",
    "        #df[df['close_direction'] != i]['close_direction']\n",
    "        '''\n",
    "        if len(a) > 0:\n",
    "            a = df.index[df[target] != i].tolist()\n",
    "        else:\n",
    "            a = a + df.index[df[target] != i].tolist()\n",
    "        '''\n",
    "        #a[i] = df.index[df[target] != i].tolist()\n",
    "        a = df.index[df[target] != i].tolist()\n",
    "        print(i,len(a))\n",
    "        if minLen == None or minLen > len(a):\n",
    "            minLen = len(a)\n",
    "    #for i in a.keys():\n",
    "    print(minLen)\n",
    "    for i in df[target].unique():\n",
    "        if not xTIndexes:\n",
    "                print(2)\n",
    "                xTIndexes = list(np.random.choice(df.index[df[target] != i].tolist(), size=minLen, replace=False))\n",
    "        else:\n",
    "            #print(OnlyNeutal)\n",
    "            xTIndexes = xTIndexes + list(np.random.choice(df.index[df[target] != i].tolist(), size=minLen, replace=False))\n",
    "\n",
    "    return (xTIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/DISNEY.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/IBM.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/BOEING.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/MCD.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/ALL_clean.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/APPLE.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/MICROSOFT.csv\n",
      "/datadrive/Sahil/code/GL/fewTrails/Datasets/GE.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk(\"/datadrive/Sahil/code/GL/fewTrails/Datasets\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "             print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def fileProcessor(csvFile,stockName):\n",
    "    dateparse = lambda x: pd.datetime.strptime(x, '%d-%m-%Y')\n",
    "    df = pd.read_csv(csvFile, parse_dates=['date'],date_parser=dateparse)\n",
    "    #df = pd.read_csv(\"/datadrive/Sahil/code/GL/fewTrails/Datasets/GE.csv\", parse_dates=['date'],date_parser=dateparse)\n",
    "\n",
    "\n",
    "    df[\"date\"]  = pd.to_datetime(df.date)\n",
    "    #type(df[\"date\"].iloc[0])\n",
    "    df = df.sort_values(by=\"date\")\n",
    "\n",
    "    df['close_delta'] = 0\n",
    "    df['close_direction'] = 0\n",
    "    df['Stock_name'] = stockName\n",
    "    for index in range(0,df.shape[0]):\n",
    "        #print(index,df.iloc[index]['close'])\n",
    "        if index == 0:\n",
    "            df['close_delta'].iloc[index] =  (float(0))\n",
    "            df['close_direction'].iloc[index] =  1\n",
    "        #elif index <= df.shape[0]-1:\n",
    "        else:\n",
    "            df['close_delta'].iloc[index] = ((df['close'].iloc[index] - df['close'].iloc[index-1])/df['close'].iloc[index-1])*100\n",
    "            if df['close_delta'].iloc[index] >= 1:\n",
    "                df['close_direction'].iloc[index] = 2\n",
    "            elif df['close_delta'].iloc[index] <= -1:\n",
    "                df['close_direction'].iloc[index] = 0\n",
    "            else:\n",
    "                df['close_direction'].iloc[index] = 1\n",
    "    return (df)\n",
    "'''\n",
    "fileCount = 0\n",
    "import os\n",
    "for root, dirs, files in os.walk(\"/datadrive/Sahil/code/GL/fewTrails/Datasets\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            print(os.path.join(root, file))\n",
    "            if fileCount == 0:\n",
    "                df = fileProcessor(os.path.join(root, file),file.split('.')[0])\n",
    "            else:\n",
    "                df = df.append(fileProcessor(os.path.join(root, file),file.split('.')[0]))\n",
    "                \n",
    "'''    \n",
    "gCount=0\n",
    "#df.apply(lambda x: featureTransform(x,df.shape[0]),axis=1)\n",
    "#df.shape[0]\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d')\n",
    "csvFile = \"/datadrive/Sahil/code/GL/fewTrails/Datasets/ALL_clean.csv\"\n",
    "df = pd.read_csv(csvFile, parse_dates=['date'],date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 22,\n",
       " 27,\n",
       " 29,\n",
       " 30,\n",
       " 32,\n",
       " 33,\n",
       " 38,\n",
       " 39,\n",
       " 41,\n",
       " 42,\n",
       " 50,\n",
       " 53,\n",
       " 60,\n",
       " 61,\n",
       " 70,\n",
       " 72,\n",
       " 75,\n",
       " 77,\n",
       " 79,\n",
       " 81,\n",
       " 84,\n",
       " 90,\n",
       " 92,\n",
       " 93,\n",
       " 95,\n",
       " 100,\n",
       " 104,\n",
       " 106,\n",
       " 109,\n",
       " 110,\n",
       " 112,\n",
       " 113,\n",
       " 116,\n",
       " 119,\n",
       " 122,\n",
       " 123,\n",
       " 125,\n",
       " 127,\n",
       " 132,\n",
       " 139,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 145,\n",
       " 147,\n",
       " 148,\n",
       " 150,\n",
       " 151,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 160,\n",
       " 163,\n",
       " 164,\n",
       " 167,\n",
       " 170,\n",
       " 172,\n",
       " 173,\n",
       " 176,\n",
       " 177,\n",
       " 185,\n",
       " 186,\n",
       " 188,\n",
       " 189,\n",
       " 191,\n",
       " 192,\n",
       " 195,\n",
       " 199,\n",
       " 203,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 219,\n",
       " 220,\n",
       " 224,\n",
       " 226,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 234,\n",
       " 240,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 254,\n",
       " 255,\n",
       " 258,\n",
       " 259,\n",
       " 264,\n",
       " 267,\n",
       " 271,\n",
       " 274,\n",
       " 277,\n",
       " 278,\n",
       " 280,\n",
       " 282,\n",
       " 283,\n",
       " 285,\n",
       " 287,\n",
       " 289,\n",
       " 295,\n",
       " 298,\n",
       " 299,\n",
       " 304,\n",
       " 306,\n",
       " 309,\n",
       " 310,\n",
       " 312,\n",
       " 313,\n",
       " 315,\n",
       " 317,\n",
       " 321,\n",
       " 325,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 335,\n",
       " 337,\n",
       " 339,\n",
       " 341,\n",
       " 343,\n",
       " 346,\n",
       " 348,\n",
       " 351,\n",
       " 352,\n",
       " 355,\n",
       " 356,\n",
       " 358,\n",
       " 359,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 369,\n",
       " 371,\n",
       " 375,\n",
       " 378,\n",
       " 382,\n",
       " 387,\n",
       " 389,\n",
       " 399,\n",
       " 402,\n",
       " 408,\n",
       " 411,\n",
       " 413,\n",
       " 420,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 438,\n",
       " 441,\n",
       " 442,\n",
       " 446,\n",
       " 458,\n",
       " 463,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 479,\n",
       " 481,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 487,\n",
       " 489,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 495,\n",
       " 498,\n",
       " 501,\n",
       " 503,\n",
       " 505,\n",
       " 506,\n",
       " 515,\n",
       " 517,\n",
       " 518,\n",
       " 528,\n",
       " 533,\n",
       " 534,\n",
       " 536,\n",
       " 544,\n",
       " 546,\n",
       " 547,\n",
       " 551,\n",
       " 556,\n",
       " 559,\n",
       " 560,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 571,\n",
       " 582,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 590,\n",
       " 598,\n",
       " 599,\n",
       " 603,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 625,\n",
       " 631,\n",
       " 652,\n",
       " 658,\n",
       " 665,\n",
       " 670,\n",
       " 671,\n",
       " 674,\n",
       " 686,\n",
       " 691,\n",
       " 692,\n",
       " 694,\n",
       " 695,\n",
       " 699,\n",
       " 700,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 706,\n",
       " 707,\n",
       " 710,\n",
       " 711,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 717,\n",
       " 722,\n",
       " 728,\n",
       " 730,\n",
       " 736,\n",
       " 741,\n",
       " 743,\n",
       " 746,\n",
       " 752,\n",
       " 753,\n",
       " 755,\n",
       " 757,\n",
       " 762,\n",
       " 765,\n",
       " 767,\n",
       " 769,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 778,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 789,\n",
       " 791,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 801,\n",
       " 802,\n",
       " 804,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 813,\n",
       " 815,\n",
       " 816,\n",
       " 818,\n",
       " 819,\n",
       " 821,\n",
       " 822,\n",
       " 824,\n",
       " 825,\n",
       " 828,\n",
       " 829,\n",
       " 834,\n",
       " 836,\n",
       " 839,\n",
       " 846,\n",
       " 858,\n",
       " 860,\n",
       " 863,\n",
       " 864,\n",
       " 867,\n",
       " 868,\n",
       " 875,\n",
       " 877,\n",
       " 880,\n",
       " 883,\n",
       " 884,\n",
       " 886,\n",
       " 891,\n",
       " 897,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 924,\n",
       " 932,\n",
       " 942,\n",
       " 947,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 977,\n",
       " 979,\n",
       " 983,\n",
       " 998,\n",
       " 1004,\n",
       " 1007,\n",
       " 1009,\n",
       " 1013,\n",
       " 1016,\n",
       " 1018,\n",
       " 1028,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1038,\n",
       " 1047,\n",
       " 1048,\n",
       " 1050,\n",
       " 1054,\n",
       " 1064,\n",
       " 1065,\n",
       " 1124,\n",
       " 1130,\n",
       " 1135,\n",
       " 1139,\n",
       " 1140,\n",
       " 1147,\n",
       " 1155,\n",
       " 1156,\n",
       " 1157,\n",
       " 1163,\n",
       " 1167,\n",
       " 1169,\n",
       " 1170,\n",
       " 1172,\n",
       " 1173,\n",
       " 1174,\n",
       " 1183,\n",
       " 1189,\n",
       " 1193,\n",
       " 1195,\n",
       " 1196,\n",
       " 1198,\n",
       " 1199,\n",
       " 1207,\n",
       " 1208,\n",
       " 1214,\n",
       " 1218,\n",
       " 1233,\n",
       " 1235,\n",
       " 1242,\n",
       " 1243,\n",
       " 1257,\n",
       " 1262,\n",
       " 1267,\n",
       " 1270,\n",
       " 1273,\n",
       " 1283,\n",
       " 1290,\n",
       " 1297,\n",
       " 1299,\n",
       " 1313,\n",
       " 1320,\n",
       " 1334,\n",
       " 1335,\n",
       " 1337,\n",
       " 1339,\n",
       " 1340,\n",
       " 1348,\n",
       " 1353,\n",
       " 1358,\n",
       " 1366,\n",
       " 1369,\n",
       " 1370,\n",
       " 1371,\n",
       " 1372,\n",
       " 1373,\n",
       " 1374,\n",
       " 1375,\n",
       " 1377,\n",
       " 1379,\n",
       " 1380,\n",
       " 1381,\n",
       " 1382,\n",
       " 1383,\n",
       " 1393,\n",
       " 1399,\n",
       " 1404,\n",
       " 1405,\n",
       " 1407,\n",
       " 1410,\n",
       " 1411,\n",
       " 1415,\n",
       " 1416,\n",
       " 1422,\n",
       " 1428,\n",
       " 1432,\n",
       " 1435,\n",
       " 1436,\n",
       " 1448,\n",
       " 1449,\n",
       " 1463,\n",
       " 1471,\n",
       " 1473,\n",
       " 1478,\n",
       " 1480,\n",
       " 1485,\n",
       " 1491,\n",
       " 1492,\n",
       " 1493,\n",
       " 1494,\n",
       " 1497,\n",
       " 1498,\n",
       " 1499,\n",
       " 1502,\n",
       " 1504,\n",
       " 1507,\n",
       " 1508,\n",
       " 1512,\n",
       " 1516,\n",
       " 1525,\n",
       " 1526,\n",
       " 1530,\n",
       " 1537,\n",
       " 1538,\n",
       " 1540,\n",
       " 1541,\n",
       " 1542,\n",
       " 1545,\n",
       " 1547,\n",
       " 1551,\n",
       " 1554,\n",
       " 1558,\n",
       " 1564,\n",
       " 1566,\n",
       " 1572,\n",
       " 1576,\n",
       " 1578,\n",
       " 1581,\n",
       " 1592,\n",
       " 1599,\n",
       " 1601,\n",
       " 1603,\n",
       " 1604,\n",
       " 1607,\n",
       " 1608,\n",
       " 1609,\n",
       " 1611,\n",
       " 1612,\n",
       " 1616,\n",
       " 1618,\n",
       " 1621,\n",
       " 1624,\n",
       " 1625,\n",
       " 1630,\n",
       " 1631,\n",
       " 1633,\n",
       " 1634,\n",
       " 1640,\n",
       " 1642,\n",
       " 1643,\n",
       " 1646,\n",
       " 1660,\n",
       " 1661,\n",
       " 1675,\n",
       " 1676,\n",
       " 1685,\n",
       " 1689,\n",
       " 1696,\n",
       " 1697,\n",
       " 1699,\n",
       " 1702,\n",
       " 1708,\n",
       " 1735,\n",
       " 1739,\n",
       " 1743,\n",
       " 1744,\n",
       " 1745,\n",
       " 1747,\n",
       " 1749,\n",
       " 1750,\n",
       " 1751,\n",
       " 1752,\n",
       " 1753,\n",
       " 1758,\n",
       " 1763,\n",
       " 1773,\n",
       " 1783,\n",
       " 1788,\n",
       " 1790,\n",
       " 1791,\n",
       " 1792,\n",
       " 1794,\n",
       " 1796,\n",
       " 1800,\n",
       " 1803,\n",
       " 1804,\n",
       " 1805,\n",
       " 1807,\n",
       " 1809,\n",
       " 1813,\n",
       " 1815,\n",
       " 1816,\n",
       " 1819,\n",
       " 1820,\n",
       " 1821,\n",
       " 1822,\n",
       " 1824,\n",
       " 1829,\n",
       " 1832,\n",
       " 1835,\n",
       " 1838,\n",
       " 1839,\n",
       " 1840,\n",
       " 1845,\n",
       " 1846,\n",
       " 1847,\n",
       " 1848,\n",
       " 1851,\n",
       " 1852,\n",
       " 1854,\n",
       " 1856,\n",
       " 1857,\n",
       " 1859,\n",
       " 1862,\n",
       " 1863,\n",
       " 1873,\n",
       " 1875,\n",
       " 1876,\n",
       " 1877,\n",
       " 1879,\n",
       " 1882,\n",
       " 1884,\n",
       " 1885,\n",
       " 1888,\n",
       " 1893,\n",
       " 1894,\n",
       " 1901,\n",
       " 1902,\n",
       " 1904,\n",
       " 1910,\n",
       " 1912,\n",
       " 1914,\n",
       " 1925,\n",
       " 1927,\n",
       " 1931,\n",
       " 1933,\n",
       " 1934,\n",
       " 1937,\n",
       " 1940,\n",
       " 1941,\n",
       " 1943,\n",
       " 1949,\n",
       " 1952,\n",
       " 1954,\n",
       " 1961,\n",
       " 1963,\n",
       " 1964,\n",
       " 1965,\n",
       " 1966,\n",
       " 1967,\n",
       " 1970,\n",
       " 1971,\n",
       " 1972,\n",
       " 1973,\n",
       " 1974,\n",
       " 1975,\n",
       " 1978,\n",
       " 1979,\n",
       " 1982,\n",
       " 1983,\n",
       " 1984,\n",
       " 1988,\n",
       " 1990,\n",
       " 1993,\n",
       " 1996,\n",
       " 1999,\n",
       " 2004,\n",
       " 2006,\n",
       " 2009,\n",
       " 2010,\n",
       " 2014,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2021,\n",
       " 2023,\n",
       " 2025,\n",
       " 2027,\n",
       " 2033,\n",
       " 2034,\n",
       " 2036,\n",
       " 2038,\n",
       " 2039,\n",
       " 2041,\n",
       " 2042,\n",
       " 2043,\n",
       " 2044,\n",
       " 2045,\n",
       " 2046,\n",
       " 2048,\n",
       " 2052,\n",
       " 2054,\n",
       " 2055,\n",
       " 2058,\n",
       " 2060,\n",
       " 2062,\n",
       " 2063,\n",
       " 2064,\n",
       " 2065,\n",
       " 2066,\n",
       " 2071,\n",
       " 2072,\n",
       " 2073,\n",
       " 2075,\n",
       " 2076,\n",
       " 2077,\n",
       " 2079,\n",
       " 2080,\n",
       " 2081,\n",
       " 2082,\n",
       " 2083,\n",
       " 2084,\n",
       " 2085,\n",
       " 2086,\n",
       " 2089,\n",
       " 2091,\n",
       " 2092,\n",
       " 2094,\n",
       " 2095,\n",
       " 2096,\n",
       " 2098,\n",
       " 2102,\n",
       " 2105,\n",
       " 2106,\n",
       " 2108,\n",
       " 2110,\n",
       " 2111,\n",
       " 2115,\n",
       " 2118,\n",
       " 2120,\n",
       " 2124,\n",
       " 2128,\n",
       " 2129,\n",
       " 2130,\n",
       " 2135,\n",
       " 2140,\n",
       " 2143,\n",
       " 2147,\n",
       " 2150,\n",
       " 2151,\n",
       " 2153,\n",
       " 2154,\n",
       " 2171,\n",
       " 2174,\n",
       " 2175,\n",
       " 2176,\n",
       " 2177,\n",
       " 2178,\n",
       " 2179,\n",
       " 2184,\n",
       " 2186,\n",
       " 2188,\n",
       " 2192,\n",
       " 2194,\n",
       " 2204,\n",
       " 2227,\n",
       " 2228,\n",
       " 2229,\n",
       " 2230,\n",
       " 2231,\n",
       " 2232,\n",
       " 2233,\n",
       " 2240,\n",
       " 2250,\n",
       " 2255,\n",
       " 2258,\n",
       " 2262,\n",
       " 2269,\n",
       " 2272,\n",
       " 2274,\n",
       " 2279,\n",
       " 2286,\n",
       " 2290,\n",
       " 2294,\n",
       " 2308,\n",
       " 2311,\n",
       " 2312,\n",
       " 2313,\n",
       " 2319,\n",
       " 2321,\n",
       " 2322,\n",
       " 2331,\n",
       " 2332,\n",
       " 2344,\n",
       " 2346,\n",
       " 2352,\n",
       " 2360,\n",
       " 2380,\n",
       " 2382,\n",
       " 2392,\n",
       " 2393,\n",
       " 2399,\n",
       " 2400,\n",
       " 2416,\n",
       " 2432,\n",
       " 2433,\n",
       " 2443,\n",
       " 2456,\n",
       " 2464,\n",
       " 2480,\n",
       " 2487,\n",
       " 2495,\n",
       " 2507,\n",
       " 2510,\n",
       " 2511,\n",
       " 2512,\n",
       " 2519,\n",
       " 2521,\n",
       " 2522,\n",
       " 2523,\n",
       " 2524,\n",
       " 2527,\n",
       " 2530,\n",
       " 2544,\n",
       " 2547,\n",
       " 2550,\n",
       " 2557,\n",
       " 2559,\n",
       " 2562,\n",
       " 2563,\n",
       " 2564,\n",
       " 2566,\n",
       " 2567,\n",
       " 2569,\n",
       " 2570,\n",
       " 2572,\n",
       " 2574,\n",
       " 2576,\n",
       " 2578,\n",
       " 2580,\n",
       " 2584,\n",
       " 2585,\n",
       " 2588,\n",
       " 2593,\n",
       " 2595,\n",
       " 2597,\n",
       " 2601,\n",
       " 2603,\n",
       " 2605,\n",
       " 2606,\n",
       " 2609,\n",
       " 2610,\n",
       " 2613,\n",
       " 2616,\n",
       " 2620,\n",
       " 2623,\n",
       " 2629,\n",
       " 2633,\n",
       " 2634,\n",
       " 2635,\n",
       " 2636,\n",
       " 2638,\n",
       " 2639,\n",
       " 2642,\n",
       " 2643,\n",
       " 2650,\n",
       " 2653,\n",
       " 2657,\n",
       " 2660,\n",
       " 2661,\n",
       " 2662,\n",
       " 2663,\n",
       " 2664,\n",
       " 2665,\n",
       " 2666,\n",
       " 2667,\n",
       " 2671,\n",
       " 2673,\n",
       " 2674,\n",
       " 2675,\n",
       " 2676,\n",
       " 2678,\n",
       " 2680,\n",
       " 2681,\n",
       " 2684,\n",
       " 2685,\n",
       " 2686,\n",
       " 2690,\n",
       " 2691,\n",
       " 2692,\n",
       " 2693,\n",
       " 2695,\n",
       " 2701,\n",
       " 2705,\n",
       " 2706,\n",
       " 2712,\n",
       " 2713,\n",
       " 2714,\n",
       " 2715,\n",
       " 2717,\n",
       " 2720,\n",
       " 2723,\n",
       " 2725,\n",
       " 2727,\n",
       " 2728,\n",
       " 2731,\n",
       " 2735,\n",
       " 2736,\n",
       " 2737,\n",
       " 2738,\n",
       " 2740,\n",
       " 2742,\n",
       " 2746,\n",
       " 2749,\n",
       " 2750,\n",
       " 2752,\n",
       " 2754,\n",
       " 2756,\n",
       " 2757,\n",
       " 2758,\n",
       " 2759,\n",
       " 2763,\n",
       " 2765,\n",
       " 2770,\n",
       " 2774,\n",
       " 2775,\n",
       " 2779,\n",
       " 2781,\n",
       " 2783,\n",
       " 2785,\n",
       " 2786,\n",
       " 2787,\n",
       " 2791,\n",
       " 2794,\n",
       " 2804,\n",
       " 2807,\n",
       " 2814,\n",
       " 2824,\n",
       " 2825,\n",
       " 2826,\n",
       " 2829,\n",
       " 2830,\n",
       " 2831,\n",
       " 2832,\n",
       " 2835,\n",
       " 2836,\n",
       " 2838,\n",
       " 2839,\n",
       " 2840,\n",
       " 2843,\n",
       " 2846,\n",
       " 2847,\n",
       " 2849,\n",
       " 2852,\n",
       " 2853,\n",
       " 2856,\n",
       " 2859,\n",
       " 2860,\n",
       " 2861,\n",
       " 2862,\n",
       " 2863,\n",
       " 2864,\n",
       " 2870,\n",
       " 2872,\n",
       " 2875,\n",
       " 2876,\n",
       " 2877,\n",
       " 2878,\n",
       " 2879,\n",
       " 2880,\n",
       " 2883,\n",
       " 2884,\n",
       " 2887,\n",
       " 2890,\n",
       " 2891,\n",
       " 2894,\n",
       " 2895,\n",
       " 2900,\n",
       " 2903,\n",
       " 2906,\n",
       " 2907,\n",
       " 2910,\n",
       " 2917,\n",
       " 2918,\n",
       " 2921,\n",
       " 2922,\n",
       " 2930,\n",
       " 2931,\n",
       " 2934,\n",
       " 2939,\n",
       " 2942,\n",
       " 2943,\n",
       " 2945,\n",
       " 2946,\n",
       " 2947,\n",
       " 2949,\n",
       " 2950,\n",
       " 2951,\n",
       " 2956,\n",
       " 2959,\n",
       " 2960,\n",
       " 2961,\n",
       " 2965,\n",
       " 2966,\n",
       " 2968,\n",
       " 2970,\n",
       " 2978,\n",
       " 2982,\n",
       " 2995,\n",
       " 2996,\n",
       " 2998,\n",
       " 2999,\n",
       " 3001,\n",
       " 3003,\n",
       " 3004,\n",
       " 3005,\n",
       " 3006,\n",
       " 3008,\n",
       " 3009,\n",
       " 3011,\n",
       " 3013,\n",
       " 3014,\n",
       " 3018,\n",
       " 3024,\n",
       " 3030,\n",
       " 3033,\n",
       " 3037,\n",
       " 3041,\n",
       " 3046,\n",
       " 3048,\n",
       " 3049,\n",
       " 3050,\n",
       " 3051,\n",
       " 3052,\n",
       " 3056,\n",
       " 3057,\n",
       " 3062,\n",
       " 3065,\n",
       " 3066,\n",
       " 3067,\n",
       " 3076,\n",
       " 3079,\n",
       " 3080,\n",
       " 3081,\n",
       " 3082,\n",
       " 3092,\n",
       " 3095,\n",
       " 3096,\n",
       " 3097,\n",
       " 3102,\n",
       " 3103,\n",
       " 3107,\n",
       " 3108,\n",
       " 3112,\n",
       " 3115,\n",
       " 3117,\n",
       " 3119,\n",
       " 3122,\n",
       " 3123,\n",
       " 3126,\n",
       " 3135,\n",
       " 3136,\n",
       " 3138,\n",
       " 3144,\n",
       " 3148,\n",
       " 3150,\n",
       " 3154,\n",
       " 3160,\n",
       " 3161,\n",
       " 3164,\n",
       " 3166,\n",
       " 3168,\n",
       " 3172,\n",
       " 3178,\n",
       " ...]"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.to_csv(\"/datadrive/Sahil/code/GL/fewTrails/Datasets/ALL_clean.csv\")\n",
    "a = df.index[df['close_direction'] != 1].tolist()\n",
    "a\n",
    "#df.iloc[700:723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Get some time series data\n",
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv\")\n",
    "#df['output']=[1,0,1,0,1,0,1,0,1,0,1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2693\n",
      "0 7446\n",
      "2 7175\n",
      "2693\n",
      "2\n",
      "(8079, 1, 6)\n",
      "(8079, 1, 6)\n",
      "MCD\n",
      "(1098, 1, 6)\n",
      "GE\n",
      "(1166, 1, 6)\n",
      "<class 'list'> <class 'list'> (1098, 1, 6)\n",
      "BOEING\n",
      "(1243, 1, 6)\n",
      "<class 'list'> <class 'list'> (2264, 1, 6)\n",
      "DISNEY\n",
      "(1166, 1, 6)\n",
      "<class 'list'> <class 'list'> (3507, 1, 6)\n",
      "APPLE\n",
      "(1065, 1, 6)\n",
      "<class 'list'> <class 'list'> (4673, 1, 6)\n",
      "MICROSOFT\n",
      "(1208, 1, 6)\n",
      "<class 'list'> <class 'list'> (5738, 1, 6)\n",
      "IBM\n",
      "(1133, 1, 6)\n",
      "<class 'list'> <class 'list'> (6946, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "window_size = 1\n",
    "input_cols = ['curr_ratio','tot_debt_tot_equity', 'oper_profit_margin','asset_turn','ret_equity','sentiment']\n",
    "\n",
    "input_cols_scale = ['curr_ratio','tot_debt_tot_equity', 'oper_profit_margin','asset_turn','ret_equity',]\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "#df_all.reset_index(drop=True)\n",
    "mydf =  pd.DataFrame(preprocessing.scale(df[input_cols_scale]),columns=input_cols_scale)\n",
    "mydf['sentiment'] = df['sentiment']\n",
    "mydf['close_direction'] = df['close_direction']\n",
    "mydf['Stock_name'] = df['Stock_name']\n",
    "train_indexes = mystratifiedOutputSampler(mydf,'close_direction')\n",
    "mydf = mydf.iloc[train_indexes]\n",
    "\n",
    "x_train,y_train=sliding_window(mydf,window_size,1,input_cols,['close_direction'])\n",
    "x_train = np.array(x_train)\n",
    "print(np.shape(x_train))\n",
    "for index,stock in enumerate(mydf['Stock_name'].unique()):\n",
    "    print(stock)\n",
    "    if index == 0:\n",
    "        x_train,y_train=sliding_window(mydf[mydf['Stock_name'] == stock],window_size,1,input_cols,['close_direction'])\n",
    "    else:\n",
    "        x_,y_=sliding_window(mydf[mydf['Stock_name'] == stock],window_size,1,input_cols,['close_direction'])\n",
    "        #x_train = np.append(x_train,x_,axis=1)\n",
    "        #x_train = np.stack((x_train,x_), axis=3)\n",
    "        #y_train = np.stack((y_train,y_), axis=3)\n",
    "        print(type(x_train),type(x_),np.shape(x_train))\n",
    "        #x_train = np.array(x_train,x_)\n",
    "        #print(x_[:,None],np.shape(x_))\n",
    "        x_train = x_train + x_\n",
    "        y_train = y_train + y_\n",
    "        #x_train = np.concatenate((x_train,x_[:,None]), axis=0)\n",
    "        #x_train=np.column_stack((x_train,x_))\n",
    "        #y_train = np.array(y_train,y_)\n",
    "x_train = np.array(x_train)\n",
    "#y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8079, 1, 6)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train1 = np.array(y_train)\n",
    "y_train1 = np.array(y_train1).reshape((-1, 1))\n",
    "#y_train = to_categorical(y_train)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "#integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y_train = onehot_encoder.fit_transform(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)[1]\n",
    "#onehot_encoder.transform(y_train1[0]).tolist()[0]\n",
    "#for i in onehot_encoder.transform(y_train1):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getBalancedSamples(x_train,proportionBYNonNeutal=.7,neutalProportionToOther=.7):\n",
    "    #proportionBYNonNeutal = .7\n",
    "    #neutalProportionToOther = .7\n",
    "    AllWithAnyOtherThanNeutal = []\n",
    "    OnlyNeutal=[]\n",
    "    #for index,i in enumerate(x_train[1:500,:,:]):\n",
    "    for index,i in enumerate(x_train[:,:,:]):\n",
    "        #print()\n",
    "        #print(i)\n",
    "        #print(i[:,5])\n",
    "        if 1 in i[:,5] or 2 in i[:,5] or 4 in i[:,5] or 5 in i[:,5]  :\n",
    "            #print(\"TRUE\")\n",
    "            if not AllWithAnyOtherThanNeutal:\n",
    "                AllWithAnyOtherThanNeutal = [index]\n",
    "            else:\n",
    "                AllWithAnyOtherThanNeutal.append(index)\n",
    "        else:\n",
    "            if not OnlyNeutal:\n",
    "                print(2)\n",
    "                OnlyNeutal = [index]\n",
    "            else:\n",
    "                #print(OnlyNeutal)\n",
    "                OnlyNeutal.append(index)\n",
    "    print (len(AllWithAnyOtherThanNeutal))\n",
    "    print (len(OnlyNeutal))\n",
    "    #AllWithAnyOtherThanNeutal[np.random.randint(0,100,size=20)]\n",
    "    proportion = .7\n",
    "    size = int(round(proportion*len(AllWithAnyOtherThanNeutal),0))\n",
    "    print(size)\n",
    "    #xTIndexesPart1 = [AllWithAnyOtherThanNeutal[i] for i in list(np.random.randint(0,100,size=size))]\n",
    "    #xTIndexesPart2 = [OnlyNeutal[i] for i in list(np.random.randint(0,100,size=int(round(size*.7)))) ]\n",
    "    #print(len(xTIndexesPart1),len(xTIndexesPart2))\n",
    "    #xTIndexes = AllWithAnyOtherThanNeutal + OnlyNeutal\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(x_train[xTIndexes,:,:], y[xTIndexes], test_size=0.2)\n",
    "    xTIndexesPart1 = list(np.random.choice(AllWithAnyOtherThanNeutal, size=size, replace=False))\n",
    "    xTIndexesPart2 = list(np.random.choice(OnlyNeutal, size=int(round(size*.7)), replace=False))\n",
    "    xTIndexes = xTIndexesPart1 + xTIndexesPart2\n",
    "    print(len(xTIndexes))\n",
    "    xTIndexesPart1 = list(np.random.choice(xTIndexes, size=len(xTIndexes), replace=False))\n",
    "    #xTIndexes = np.sort(xTIndexes)\n",
    "    return(xTIndexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['close_direction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_indexes = mystratifiedOutputSampler(df,'close_direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782\n",
      "1772 7044\n"
     ]
    }
   ],
   "source": [
    "#onehot_encoded[0:30]\n",
    "print(len(a))\n",
    "print(len(AllWithAnyOtherThanNeutal), len(OnlyNeutal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_indexes = getBalancedSamples(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "481\n",
      "7598\n",
      "337\n",
      "573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train\n",
    "train_indexes = getBalancedSamples(x_train)\n",
    "X_train = x_train[train_indexes]\n",
    "Y_train = y_train[train_indexes]\n",
    "\n",
    "#X_train = x_train\n",
    "#Y_train = y_train\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>curr_ratio</th>\n",
       "      <th>tot_debt_tot_equity</th>\n",
       "      <th>oper_profit_margin</th>\n",
       "      <th>asset_turn</th>\n",
       "      <th>ret_equity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close_delta</th>\n",
       "      <th>close_direction</th>\n",
       "      <th>Stock_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1259</td>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>50.32</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>18.3176</td>\n",
       "      <td>0.144</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1258</td>\n",
       "      <td>2012-11-06</td>\n",
       "      <td>50.47</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>18.3176</td>\n",
       "      <td>0.144</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.298092</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1257</td>\n",
       "      <td>2012-11-07</td>\n",
       "      <td>50.08</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>18.3176</td>\n",
       "      <td>0.144</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.772736</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1256</td>\n",
       "      <td>2012-11-08</td>\n",
       "      <td>50.04</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>18.3176</td>\n",
       "      <td>0.144</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.079872</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>47.06</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>18.3176</td>\n",
       "      <td>0.144</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.955236</td>\n",
       "      <td>0</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1254</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>47.45</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>18.3176</td>\n",
       "      <td>0.144</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828729</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date  close  curr_ratio  tot_debt_tot_equity  \\\n",
       "0        1259 2012-11-05  50.32      1.0699               0.3411   \n",
       "1        1258 2012-11-06  50.47      1.0699               0.3411   \n",
       "2        1257 2012-11-07  50.08      1.0699               0.3411   \n",
       "3        1256 2012-11-08  50.04      1.0699               0.3411   \n",
       "4        1255 2012-11-09  47.06      1.0699               0.3411   \n",
       "5        1254 2012-11-12  47.45      1.0699               0.3411   \n",
       "\n",
       "   oper_profit_margin  asset_turn  ret_equity  sentiment  close_delta  \\\n",
       "0             18.3176       0.144      3.3128          3     0.000000   \n",
       "1             18.3176       0.144      3.3128          3     0.298092   \n",
       "2             18.3176       0.144      3.3128          3    -0.772736   \n",
       "3             18.3176       0.144      3.3128          3    -0.079872   \n",
       "4             18.3176       0.144      3.3128          3    -5.955236   \n",
       "5             18.3176       0.144      3.3128          3     0.828729   \n",
       "\n",
       "   close_direction Stock_name  \n",
       "0                1     DISNEY  \n",
       "1                1     DISNEY  \n",
       "2                1     DISNEY  \n",
       "3                1     DISNEY  \n",
       "4                0     DISNEY  \n",
       "5                1     DISNEY  "
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.where(y_train[train_indexes][:,0] !=0)\n",
    "\n",
    "#y_train[train_indexes][5,:]\n",
    "df.iloc[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mygpu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, activation=\"softsign\", return_sequences=True, input_shape=(1, 6), recurrent_activation=\"hard_sigmoid\")`\n",
      "/home/mygpu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_shape = number of time-steps, number-of-features\n",
    "model.add(LSTM(128,input_shape=(window_size,len(input_cols)),\n",
    "               activation='softsign', \n",
    "               inner_activation='hard_sigmoid', \n",
    "               return_sequences=True))\n",
    "model.add(LSTM(128, activation='softsign', recurrent_activation='hard_sigmoid'))\n",
    "#model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(TimeDistributedDense(11))\n",
    "#model.add(Dense(128))\n",
    "model.add(Dense(128,activation='tanh'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(output_dim=np.shape(y_train)[1], activation='softmax'))\n",
    "#model.add(Activation('sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_59 (LSTM)               (None, 1, 128)            69120     \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 227,651\n",
      "Trainable params: 227,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 573 samples, validate on 573 samples\n",
      "Epoch 1/5\n",
      "573/573 [==============================] - 8s - loss: 1.0983 - val_loss: 1.0899\n",
      "Epoch 2/5\n",
      "573/573 [==============================] - 6s - loss: 1.0828 - val_loss: 1.0556\n",
      "Epoch 3/5\n",
      "573/573 [==============================] - 6s - loss: 1.0686 - val_loss: 1.0404\n",
      "Epoch 4/5\n",
      "573/573 [==============================] - 6s - loss: 1.0491 - val_loss: 0.9974\n",
      "Epoch 5/5\n",
      "573/573 [==============================] - 6s - loss: 1.0275 - val_loss: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd77a49c978>"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=1,\n",
    "          epochs=5,\n",
    "          validation_data=(X_train, Y_train))\n",
    "#score, acc = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/573 [============================>.] - ETA: 0s\n",
      "Test score: 0.968456945546\n",
      "[[ 0.2302704   0.52216446  0.24756512]\n",
      " [ 0.21386819  0.62846506  0.15766674]\n",
      " [ 0.11151202  0.19101492  0.69747311]\n",
      " ..., \n",
      " [ 0.20812508  0.60959494  0.18227994]\n",
      " [ 0.17636201  0.35002598  0.47361198]\n",
      " [ 0.21279116  0.44756529  0.33964354]]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, Y_train,batch_size=1)\n",
    "print()\n",
    "print('Test score:', score)\n",
    "print(model.predict(X_train))\n",
    "#print('Test accuracy:', confusion_matrix(Y_train,model.predict_classes(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/573 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "#model.predict(x_train)\n",
    "a = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 1, 1, 0, 0, 2, 0, 1, 1, 2, 0, 0, 2, 0, 1, 0, 1, 1, 1,\n",
       "       2, 1, 1, 1, 0, 1, 2, 2, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 0,\n",
       "       2, 2, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1,\n",
       "       2, 2, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 2, 1, 1, 0, 0, 2, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 0, 2, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 2, 2,\n",
       "       1, 2, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1,\n",
       "       1, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 0, 1, 2, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0,\n",
       "       2, 2, 1, 0, 1, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0,\n",
       "       0, 1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2,\n",
       "       2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = set(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train\n",
    "#list(y_train1)\n",
    "#onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoder.active_features_\n",
    "labels = Y_train.dot(onehot_encoder.active_features_).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 2, 1, 1, 2, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 1, 1, 1,\n",
       "       2, 1, 0, 1, 0, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1,\n",
       "       2, 2, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       2, 2, 2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1,\n",
       "       2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 1, 0,\n",
       "       0, 2, 1, 0, 0, 0, 2, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 1, 2, 1,\n",
       "       1, 0, 2, 1, 2, 0, 1, 2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 0, 2, 1, 2, 1,\n",
       "       1, 2, 2, 1, 2, 0, 1, 0, 0, 1, 0, 0, 2, 1, 2, 0, 2, 1, 1, 0, 2, 0, 1,\n",
       "       1, 1, 2, 2, 1, 2, 0, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 2, 0, 2, 1, 1, 2,\n",
       "       0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 1, 1,\n",
       "       0, 2, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0,\n",
       "       1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 1, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 0, 1,\n",
       "       1, 1, 0, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 1, 2, 2, 1, 1, 0,\n",
       "       2, 2, 1, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 2, 0, 0, 1, 2, 2, 1,\n",
       "       1, 2, 1, 2, 1, 2, 0, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 1, 1, 1, 0, 1, 2,\n",
       "       2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 2, 1, 2, 0, 1, 2, 2, 1, 1, 1,\n",
       "       2, 1, 1, 1, 0, 0, 2, 1, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0,\n",
       "       0, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 2, 2, 2,\n",
       "       0, 1, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1,\n",
       "       0, 1, 0, 1, 2, 2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 2, 1, 2, 0, 1,\n",
       "       1, 0, 1, 2, 0, 2, 0, 1, 1, 2, 0, 2, 2, 2, 1, 1, 2, 1, 2, 0, 0])"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-652-7131a3e0df6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stock'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmydf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stock_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2423\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreindexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   2547\u001b[0m                     \u001b[0;31m# duplicate axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m                     \u001b[0;31m# other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   2542\u001b[0m                 \u001b[0;31m# GH 4107\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2543\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2544\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2545\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   2285\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fillna'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[0;32m-> 2229\u001b[0;31m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   2245\u001b[0m             obj = obj._reindex_with_indexers({axis: [new_index, indexer]},\n\u001b[1;32m   2246\u001b[0m                                              \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m                                              copy=copy, allow_dups=False)\n\u001b[0m\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   2339\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m                                                 copy=copy)\n\u001b[0m\u001b[1;32m   2342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3584\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mygpu/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(columns=['predicted','actual'])\n",
    "output['predicted'] = a.tolist()\n",
    "output['actual'] = labels.tolist()\n",
    "output['Stock'] = mydf.iloc[train_indexes]['Stock_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted  actual\n",
       "0            1       2\n",
       "1            1       1\n",
       "2            2       2\n",
       "3            1       1\n",
       "4            1       2\n",
       "5            1       1\n",
       "6            1       1\n",
       "7            0       2\n",
       "8            0       0\n",
       "9            2       1\n",
       "10           0       0\n",
       "11           1       0\n",
       "12           1       2\n",
       "13           2       2\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           2       2\n",
       "17           0       0\n",
       "18           1       2\n",
       "19           0       0\n",
       "20           1       1\n",
       "21           1       1\n",
       "22           1       1\n",
       "23           2       2\n",
       "24           1       1\n",
       "25           1       0\n",
       "26           1       1\n",
       "27           0       0\n",
       "28           1       1\n",
       "29           2       2\n",
       "..         ...     ...\n",
       "543          1       1\n",
       "544          1       2\n",
       "545          1       0\n",
       "546          2       2\n",
       "547          1       2\n",
       "548          2       1\n",
       "549          1       2\n",
       "550          1       0\n",
       "551          1       1\n",
       "552          2       1\n",
       "553          1       0\n",
       "554          1       1\n",
       "555          1       2\n",
       "556          2       0\n",
       "557          1       2\n",
       "558          1       0\n",
       "559          1       1\n",
       "560          2       1\n",
       "561          1       2\n",
       "562          1       0\n",
       "563          2       2\n",
       "564          1       2\n",
       "565          1       2\n",
       "566          1       1\n",
       "567          1       1\n",
       "568          1       2\n",
       "569          1       1\n",
       "570          1       2\n",
       "571          2       0\n",
       "572          1       0\n",
       "\n",
       "[573 rows x 2 columns]"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_ratio</th>\n",
       "      <th>tot_debt_tot_equity</th>\n",
       "      <th>oper_profit_margin</th>\n",
       "      <th>asset_turn</th>\n",
       "      <th>ret_equity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close_direction</th>\n",
       "      <th>Stock_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>-0.795108</td>\n",
       "      <td>-0.154544</td>\n",
       "      <td>0.518957</td>\n",
       "      <td>0.228928</td>\n",
       "      <td>-0.076682</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>APPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>-0.705208</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>-0.890216</td>\n",
       "      <td>-0.150399</td>\n",
       "      <td>-0.074510</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>1.346507</td>\n",
       "      <td>0.142171</td>\n",
       "      <td>0.272654</td>\n",
       "      <td>-1.849915</td>\n",
       "      <td>-0.155432</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>-0.762454</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>1.135005</td>\n",
       "      <td>0.203037</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>-0.505251</td>\n",
       "      <td>0.096075</td>\n",
       "      <td>-0.769904</td>\n",
       "      <td>1.385129</td>\n",
       "      <td>0.165916</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>-0.923038</td>\n",
       "      <td>-0.099274</td>\n",
       "      <td>0.744392</td>\n",
       "      <td>0.793777</td>\n",
       "      <td>-0.062871</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>-0.824672</td>\n",
       "      <td>-0.168617</td>\n",
       "      <td>0.518749</td>\n",
       "      <td>0.298498</td>\n",
       "      <td>-0.086502</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>APPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>0.601370</td>\n",
       "      <td>-2.108197</td>\n",
       "      <td>1.119184</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>-1.018265</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>-0.277073</td>\n",
       "      <td>-0.208739</td>\n",
       "      <td>0.640168</td>\n",
       "      <td>1.527583</td>\n",
       "      <td>-0.067632</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>APPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>1.311703</td>\n",
       "      <td>-0.203056</td>\n",
       "      <td>0.818624</td>\n",
       "      <td>-0.534695</td>\n",
       "      <td>-0.110415</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>-0.466280</td>\n",
       "      <td>-0.019311</td>\n",
       "      <td>-0.957020</td>\n",
       "      <td>1.426540</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>-0.530648</td>\n",
       "      <td>-0.059711</td>\n",
       "      <td>0.195523</td>\n",
       "      <td>0.359787</td>\n",
       "      <td>-0.102929</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.935536</td>\n",
       "      <td>-0.182876</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>-0.258068</td>\n",
       "      <td>-0.139741</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-0.936879</td>\n",
       "      <td>-0.162138</td>\n",
       "      <td>0.406462</td>\n",
       "      <td>-0.166964</td>\n",
       "      <td>-0.123702</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>0.287189</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>-0.154231</td>\n",
       "      <td>-1.328134</td>\n",
       "      <td>-0.141478</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>-0.397075</td>\n",
       "      <td>-0.089105</td>\n",
       "      <td>-0.746269</td>\n",
       "      <td>1.651817</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>0.198229</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>-0.555041</td>\n",
       "      <td>-1.331447</td>\n",
       "      <td>-0.164129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7225</th>\n",
       "      <td>0.466586</td>\n",
       "      <td>-0.062154</td>\n",
       "      <td>0.345866</td>\n",
       "      <td>-0.932243</td>\n",
       "      <td>-0.097679</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>-0.466280</td>\n",
       "      <td>-0.019311</td>\n",
       "      <td>-0.957020</td>\n",
       "      <td>1.426540</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>-0.705208</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>-0.890216</td>\n",
       "      <td>-0.150399</td>\n",
       "      <td>-0.074510</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>-0.647290</td>\n",
       "      <td>-0.019802</td>\n",
       "      <td>-0.176514</td>\n",
       "      <td>0.830218</td>\n",
       "      <td>0.022465</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>1.043883</td>\n",
       "      <td>-0.068035</td>\n",
       "      <td>0.170869</td>\n",
       "      <td>-1.107826</td>\n",
       "      <td>-0.080535</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>-0.668791</td>\n",
       "      <td>0.102594</td>\n",
       "      <td>-0.323360</td>\n",
       "      <td>0.045062</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>-0.543683</td>\n",
       "      <td>0.145941</td>\n",
       "      <td>-0.369290</td>\n",
       "      <td>0.129541</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>-0.029411</td>\n",
       "      <td>-0.207876</td>\n",
       "      <td>0.416638</td>\n",
       "      <td>0.288560</td>\n",
       "      <td>-0.115271</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>APPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>-0.620817</td>\n",
       "      <td>-0.108024</td>\n",
       "      <td>0.808643</td>\n",
       "      <td>0.702672</td>\n",
       "      <td>-0.068135</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>-0.601601</td>\n",
       "      <td>9.023716</td>\n",
       "      <td>-0.659919</td>\n",
       "      <td>1.164821</td>\n",
       "      <td>10.962175</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8188</th>\n",
       "      <td>2.155879</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>-0.454477</td>\n",
       "      <td>-1.911204</td>\n",
       "      <td>-0.168681</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>-1.026108</td>\n",
       "      <td>-0.165285</td>\n",
       "      <td>0.501712</td>\n",
       "      <td>-0.302792</td>\n",
       "      <td>-0.123711</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>-0.824672</td>\n",
       "      <td>-0.168617</td>\n",
       "      <td>0.518749</td>\n",
       "      <td>0.298498</td>\n",
       "      <td>-0.086502</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>APPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>1.487069</td>\n",
       "      <td>-0.200149</td>\n",
       "      <td>1.011066</td>\n",
       "      <td>0.051688</td>\n",
       "      <td>-0.083035</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>1.012707</td>\n",
       "      <td>-0.185199</td>\n",
       "      <td>0.580786</td>\n",
       "      <td>-0.201749</td>\n",
       "      <td>-0.111686</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>-0.669732</td>\n",
       "      <td>-0.076678</td>\n",
       "      <td>-0.693478</td>\n",
       "      <td>1.042244</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>-0.637884</td>\n",
       "      <td>-0.145556</td>\n",
       "      <td>-0.706440</td>\n",
       "      <td>1.542491</td>\n",
       "      <td>-0.076859</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>-0.714212</td>\n",
       "      <td>-0.049714</td>\n",
       "      <td>-0.639045</td>\n",
       "      <td>1.615375</td>\n",
       "      <td>0.111392</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>-0.705208</td>\n",
       "      <td>0.081776</td>\n",
       "      <td>-0.890216</td>\n",
       "      <td>-0.150399</td>\n",
       "      <td>-0.074510</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>-0.573113</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>-0.808797</td>\n",
       "      <td>1.446417</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>-0.824672</td>\n",
       "      <td>-0.168617</td>\n",
       "      <td>0.518749</td>\n",
       "      <td>0.298498</td>\n",
       "      <td>-0.086502</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>APPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>-0.603348</td>\n",
       "      <td>0.100894</td>\n",
       "      <td>-0.566084</td>\n",
       "      <td>-0.057638</td>\n",
       "      <td>-0.037916</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>1.574819</td>\n",
       "      <td>-0.200202</td>\n",
       "      <td>0.883144</td>\n",
       "      <td>-0.552916</td>\n",
       "      <td>-0.111185</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7554</th>\n",
       "      <td>2.237582</td>\n",
       "      <td>0.100456</td>\n",
       "      <td>0.328250</td>\n",
       "      <td>-1.846602</td>\n",
       "      <td>-0.154178</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>1.619433</td>\n",
       "      <td>-0.179159</td>\n",
       "      <td>0.641778</td>\n",
       "      <td>-0.672180</td>\n",
       "      <td>-0.121814</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.957574</td>\n",
       "      <td>-0.172693</td>\n",
       "      <td>-0.106641</td>\n",
       "      <td>-0.380645</td>\n",
       "      <td>-0.148198</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>-0.601601</td>\n",
       "      <td>9.023716</td>\n",
       "      <td>-0.659919</td>\n",
       "      <td>1.164821</td>\n",
       "      <td>10.962175</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>-0.715421</td>\n",
       "      <td>0.122694</td>\n",
       "      <td>-0.431263</td>\n",
       "      <td>0.293529</td>\n",
       "      <td>-0.007668</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>1.971106</td>\n",
       "      <td>-0.190258</td>\n",
       "      <td>0.777297</td>\n",
       "      <td>-0.064264</td>\n",
       "      <td>-0.095904</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.786508</td>\n",
       "      <td>-0.175163</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.561198</td>\n",
       "      <td>-0.143953</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>-0.538711</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>-0.370422</td>\n",
       "      <td>0.187516</td>\n",
       "      <td>0.046374</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.847382</td>\n",
       "      <td>-0.180818</td>\n",
       "      <td>-0.114741</td>\n",
       "      <td>-0.324326</td>\n",
       "      <td>-0.148232</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>-0.530245</td>\n",
       "      <td>-0.059485</td>\n",
       "      <td>-0.772055</td>\n",
       "      <td>1.214515</td>\n",
       "      <td>-0.018050</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>1.024264</td>\n",
       "      <td>-0.159988</td>\n",
       "      <td>0.521013</td>\n",
       "      <td>-0.756659</td>\n",
       "      <td>-0.112299</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>1.619433</td>\n",
       "      <td>-0.179159</td>\n",
       "      <td>0.641778</td>\n",
       "      <td>-0.672180</td>\n",
       "      <td>-0.121814</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>-0.530245</td>\n",
       "      <td>-0.059485</td>\n",
       "      <td>-0.772055</td>\n",
       "      <td>1.214515</td>\n",
       "      <td>-0.018050</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>-0.243075</td>\n",
       "      <td>0.061330</td>\n",
       "      <td>0.663501</td>\n",
       "      <td>0.614880</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>1.487069</td>\n",
       "      <td>-0.200149</td>\n",
       "      <td>1.011066</td>\n",
       "      <td>0.051688</td>\n",
       "      <td>-0.083035</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>-0.573113</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>-0.808797</td>\n",
       "      <td>1.446417</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>BOEING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>-0.754660</td>\n",
       "      <td>-0.182040</td>\n",
       "      <td>0.497995</td>\n",
       "      <td>-0.243160</td>\n",
       "      <td>-0.128421</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>1.359005</td>\n",
       "      <td>-0.199870</td>\n",
       "      <td>0.652923</td>\n",
       "      <td>-0.395553</td>\n",
       "      <td>-0.112780</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-0.602004</td>\n",
       "      <td>-0.182717</td>\n",
       "      <td>0.332413</td>\n",
       "      <td>-0.329296</td>\n",
       "      <td>-0.134917</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>DISNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>1.742660</td>\n",
       "      <td>-0.149273</td>\n",
       "      <td>0.325879</td>\n",
       "      <td>-0.521444</td>\n",
       "      <td>-0.109847</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>MICROSOFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      curr_ratio  tot_debt_tot_equity  oper_profit_margin  asset_turn  \\\n",
       "5645   -0.795108            -0.154544            0.518957    0.228928   \n",
       "2416   -0.705208             0.081776           -0.890216   -0.150399   \n",
       "7410    1.346507             0.142171            0.272654   -1.849915   \n",
       "1324   -0.762454             0.006565            0.620370    1.135005   \n",
       "3395   -0.505251             0.096075           -0.769904    1.385129   \n",
       "3791   -0.923038            -0.099274            0.744392    0.793777   \n",
       "5583   -0.824672            -0.168617            0.518749    0.298498   \n",
       "4976    0.601370            -2.108197            1.119184    0.346535   \n",
       "5171   -0.277073            -0.208739            0.640168    1.527583   \n",
       "6169    1.311703            -0.203056            0.818624   -0.534695   \n",
       "3353   -0.466280            -0.019311           -0.957020    1.426540   \n",
       "4391   -0.530648            -0.059711            0.195523    0.359787   \n",
       "301    -0.935536            -0.182876            0.085186   -0.258068   \n",
       "1231   -0.936879            -0.162138            0.406462   -0.166964   \n",
       "8328    0.287189             0.010415           -0.154231   -1.328134   \n",
       "3084   -0.397075            -0.089105           -0.746269    1.651817   \n",
       "8612    0.198229             0.008158           -0.555041   -1.331447   \n",
       "7225    0.466586            -0.062154            0.345866   -0.932243   \n",
       "3358   -0.466280            -0.019311           -0.957020    1.426540   \n",
       "2430   -0.705208             0.081776           -0.890216   -0.150399   \n",
       "1273   -0.647290            -0.019802           -0.176514    0.830218   \n",
       "7395    1.043883            -0.068035            0.170869   -1.107826   \n",
       "2283   -0.668791             0.102594           -0.323360    0.045062   \n",
       "2194   -0.543683             0.145941           -0.369290    0.129541   \n",
       "5129   -0.029411            -0.207876            0.416638    0.288560   \n",
       "4018   -0.620817            -0.108024            0.808643    0.702672   \n",
       "3683   -0.601601             9.023716           -0.659919    1.164821   \n",
       "8188    2.155879             0.024515           -0.454477   -1.911204   \n",
       "1143   -1.026108            -0.165285            0.501712   -0.302792   \n",
       "5568   -0.824672            -0.168617            0.518749    0.298498   \n",
       "...          ...                  ...                 ...         ...   \n",
       "6219    1.487069            -0.200149            1.011066    0.051688   \n",
       "6726    1.012707            -0.185199            0.580786   -0.201749   \n",
       "3133   -0.669732            -0.076678           -0.693478    1.042244   \n",
       "3048   -0.637884            -0.145556           -0.706440    1.542491   \n",
       "3305   -0.714212            -0.049714           -0.639045    1.615375   \n",
       "2400   -0.705208             0.081776           -0.890216   -0.150399   \n",
       "2598   -0.573113             0.005490           -0.808797    1.446417   \n",
       "5555   -0.824672            -0.168617            0.518749    0.298498   \n",
       "2494   -0.603348             0.100894           -0.566084   -0.057638   \n",
       "6368    1.574819            -0.200202            0.883144   -0.552916   \n",
       "7554    2.237582             0.100456            0.328250   -1.846602   \n",
       "6748    1.619433            -0.179159            0.641778   -0.672180   \n",
       "94     -0.957574            -0.172693           -0.106641   -0.380645   \n",
       "3678   -0.601601             9.023716           -0.659919    1.164821   \n",
       "1616   -0.715421             0.122694           -0.431263    0.293529   \n",
       "6485    1.971106            -0.190258            0.777297   -0.064264   \n",
       "152    -0.786508            -0.175163            0.004892   -0.561198   \n",
       "1923   -0.538711             0.193365           -0.370422    0.187516   \n",
       "31     -0.847382            -0.180818           -0.114741   -0.324326   \n",
       "2691   -0.530245            -0.059485           -0.772055    1.214515   \n",
       "6913    1.024264            -0.159988            0.521013   -0.756659   \n",
       "6770    1.619433            -0.179159            0.641778   -0.672180   \n",
       "2742   -0.530245            -0.059485           -0.772055    1.214515   \n",
       "4531   -0.243075             0.061330            0.663501    0.614880   \n",
       "6195    1.487069            -0.200149            1.011066    0.051688   \n",
       "2559   -0.573113             0.005490           -0.808797    1.446417   \n",
       "425    -0.754660            -0.182040            0.497995   -0.243160   \n",
       "6307    1.359005            -0.199870            0.652923   -0.395553   \n",
       "217    -0.602004            -0.182717            0.332413   -0.329296   \n",
       "6939    1.742660            -0.149273            0.325879   -0.521444   \n",
       "\n",
       "      ret_equity  sentiment  close_direction Stock_name  \n",
       "5645   -0.076682          3                0      APPLE  \n",
       "2416   -0.074510          3                2        IBM  \n",
       "7410   -0.155432          4                2         GE  \n",
       "1324    0.203037          3                1        IBM  \n",
       "3395    0.165916          3                0     BOEING  \n",
       "3791   -0.062871          3                1        MCD  \n",
       "5583   -0.086502          4                2      APPLE  \n",
       "4976   -1.018265          3                1        MCD  \n",
       "5171   -0.067632          3                1      APPLE  \n",
       "6169   -0.110415          3                2  MICROSOFT  \n",
       "3353    0.003342          3                1     BOEING  \n",
       "4391   -0.102929          3                1        MCD  \n",
       "301    -0.139741          3                1     DISNEY  \n",
       "1231   -0.123702          3                1     DISNEY  \n",
       "8328   -0.141478          3                1         GE  \n",
       "3084    0.010955          3                1     BOEING  \n",
       "8612   -0.164129          2                2         GE  \n",
       "7225   -0.097679          3                1  MICROSOFT  \n",
       "3358    0.003342          3                2     BOEING  \n",
       "2430   -0.074510          3                1        IBM  \n",
       "1273    0.022465          3                2        IBM  \n",
       "7395   -0.080535          3                2  MICROSOFT  \n",
       "2283    0.010416          3                1        IBM  \n",
       "2194    0.000076          3                2        IBM  \n",
       "5129   -0.115271          3                1      APPLE  \n",
       "4018   -0.068135          3                2        MCD  \n",
       "3683   10.962175          3                1     BOEING  \n",
       "8188   -0.168681          3                1         GE  \n",
       "1143   -0.123711          3                1     DISNEY  \n",
       "5568   -0.086502          3                1      APPLE  \n",
       "...          ...        ...              ...        ...  \n",
       "6219   -0.083035          3                1  MICROSOFT  \n",
       "6726   -0.111686          3                1  MICROSOFT  \n",
       "3133    0.010474          3                1     BOEING  \n",
       "3048   -0.076859          3                0     BOEING  \n",
       "3305    0.111392          3                0     BOEING  \n",
       "2400   -0.074510          3                0        IBM  \n",
       "2598    0.007528          3                1     BOEING  \n",
       "5555   -0.086502          3                1      APPLE  \n",
       "2494   -0.037916          3                1        IBM  \n",
       "6368   -0.111185          3                0  MICROSOFT  \n",
       "7554   -0.154178          3                1         GE  \n",
       "6748   -0.121814          3                1  MICROSOFT  \n",
       "94     -0.148198          3                1     DISNEY  \n",
       "3678   10.962175          3                1     BOEING  \n",
       "1616   -0.007668          3                2        IBM  \n",
       "6485   -0.095904          3                0  MICROSOFT  \n",
       "152    -0.143953          3                1     DISNEY  \n",
       "1923    0.046374          3                1        IBM  \n",
       "31     -0.148232          3                1     DISNEY  \n",
       "2691   -0.018050          3                0     BOEING  \n",
       "6913   -0.112299          3                2  MICROSOFT  \n",
       "6770   -0.121814          3                1  MICROSOFT  \n",
       "2742   -0.018050          3                2     BOEING  \n",
       "4531   -0.000039          3                1        MCD  \n",
       "6195   -0.083035          3                1  MICROSOFT  \n",
       "2559    0.007528          3                2     BOEING  \n",
       "425    -0.128421          3                1     DISNEY  \n",
       "6307   -0.112780          3                2  MICROSOFT  \n",
       "217    -0.134917          3                1     DISNEY  \n",
       "6939   -0.109847          3                0  MICROSOFT  \n",
       "\n",
       "[573 rows x 8 columns]"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf.iloc[train_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[[[]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[0] = ALL[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append(ALL[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
